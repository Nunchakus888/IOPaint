"""
ä½å¯¹æ¯”åº¦æ°´å°æ£€æµ‹å™¨ - ä¸“é—¨é’ˆå¯¹å¤æ‚èƒŒæ™¯ä¸‹çš„åŠé€æ˜æ°´å°
==========================================================

æ ¸å¿ƒé—®é¢˜ï¼š
- æ°´å°é¢œè‰²ï¼ˆç°ç™½è‰²ï¼‰ä¸èƒŒæ™¯ï¼ˆé›ªåœ°ï¼‰æå…¶ç›¸è¿‘
- æ°´å°é€æ˜åº¦å¾ˆä½ï¼Œå¯¹æ¯”åº¦æä½
- å¸¸è§„è¾¹ç¼˜æ£€æµ‹ã€é˜ˆå€¼æ–¹æ³•å®Œå…¨å¤±æ•ˆ

æ ¸å¿ƒç†è®ºï¼š

1. é«˜é€šæ»¤æ³¢å¢å¼ºæ³•
   - æ°´å°æ–‡å­—æœ‰é«˜é¢‘è¾¹ç¼˜ä¿¡æ¯
   - èƒŒæ™¯é€šå¸¸æ˜¯å¹³æ»‘çš„ä½é¢‘ä¿¡æ¯
   - é«˜é€šæ»¤æ³¢å¯ä»¥çªå‡ºæ°´å°è¾¹ç¼˜
   
2. å¤šå°ºåº¦é«˜æ–¯å·®åˆ† (DoG)
   - ä½¿ç”¨ä¸åŒsigmaçš„é«˜æ–¯æ¨¡ç³Šä¹‹å·®
   - å¯ä»¥æ£€æµ‹ç‰¹å®šå°ºåº¦çš„è¾¹ç¼˜
   - æ–‡å­—ç¬”ç”»æœ‰ç‰¹å®šçš„å®½åº¦èŒƒå›´

3. å±€éƒ¨è‡ªé€‚åº”å¢å¼º
   - åœ¨æå°çš„å±€éƒ¨çª—å£å†…è¿›è¡Œå¯¹æ¯”åº¦å¢å¼º
   - å³ä½¿å…¨å±€å¯¹æ¯”åº¦å¾ˆä½ï¼Œå±€éƒ¨å¯èƒ½ä»æœ‰å·®å¼‚

4. Laplaciané‡‘å­—å¡”åˆ†è§£
   - å°†å›¾åƒåˆ†è§£ä¸ºä¸åŒé¢‘ç‡å¸¦
   - æ°´å°å¯èƒ½åœ¨æŸä¸ªç‰¹å®šé¢‘ç‡å¸¦æ›´æ˜æ˜¾

5. å¼•å¯¼æ»¤æ³¢åˆ†å±‚
   - å°†å›¾åƒåˆ†ä¸ºbaseå±‚å’Œdetailå±‚
   - æ°´å°ä½œä¸ºå åŠ å±‚ï¼Œå¯èƒ½åœ¨detailå±‚æ›´æ˜æ˜¾
"""

import cv2
import numpy as np
from typing import Optional, Tuple, List
import os


class LowContrastWatermarkDetector:
    """
    ä½å¯¹æ¯”åº¦æ°´å°æ£€æµ‹å™¨
    
    ä¸“é—¨é’ˆå¯¹ï¼š
    - åŠé€æ˜æ°´å°
    - ä¸èƒŒæ™¯é¢œè‰²ç›¸è¿‘çš„æ°´å°
    - å¤æ‚çº¹ç†èƒŒæ™¯ä¸‹çš„æ°´å°
    """
    
    def __init__(self, debug: bool = True):
        self.debug = debug
        
    def detect(self, image: np.ndarray, output_dir: Optional[str] = None) -> np.ndarray:
        """
        ä¸»æ£€æµ‹æµç¨‹
        """
        h, w = image.shape[:2]
        
        print("=" * 60)
        print("ä½å¯¹æ¯”åº¦æ°´å°æ£€æµ‹å™¨")
        print("=" * 60)
        
        # ===== ç­–ç•¥1: é«˜é€šæ»¤æ³¢å¢å¼º =====
        hp_mask = self._highpass_enhancement(image)
        if self.debug and output_dir:
            cv2.imwrite(os.path.join(output_dir, 'lc_1_highpass.png'), hp_mask)
        
        # ===== ç­–ç•¥2: å¤šå°ºåº¦DoG =====
        dog_mask = self._multiscale_dog(image)
        if self.debug and output_dir:
            cv2.imwrite(os.path.join(output_dir, 'lc_2_dog.png'), dog_mask)
        
        # ===== ç­–ç•¥3: æç«¯å±€éƒ¨å¢å¼º =====
        local_mask = self._extreme_local_enhancement(image)
        if self.debug and output_dir:
            cv2.imwrite(os.path.join(output_dir, 'lc_3_local.png'), local_mask)
        
        # ===== ç­–ç•¥4: å¼•å¯¼æ»¤æ³¢åˆ†å±‚ =====
        guided_mask = self._guided_filter_layer(image)
        if self.debug and output_dir:
            cv2.imwrite(os.path.join(output_dir, 'lc_4_guided.png'), guided_mask)
        
        # ===== ç­–ç•¥5: Laplacianå¢å¼º =====
        lap_mask = self._laplacian_enhancement(image)
        if self.debug and output_dir:
            cv2.imwrite(os.path.join(output_dir, 'lc_5_laplacian.png'), lap_mask)
        
        # ===== èåˆç­–ç•¥ =====
        # å¯¹äºä½å¯¹æ¯”åº¦æ°´å°ï¼Œæ”¾å®½èåˆæ¡ä»¶
        combined = (hp_mask.astype(np.float32) / 255 + 
                   dog_mask.astype(np.float32) / 255 + 
                   local_mask.astype(np.float32) / 255 +
                   guided_mask.astype(np.float32) / 255 +
                   lap_mask.astype(np.float32) / 255)
        
        # è‡³å°‘1ç§æ–¹æ³•æ£€æµ‹åˆ°ï¼ˆæ”¾å®½æ¡ä»¶ï¼‰
        final_mask = (combined >= 1.5).astype(np.uint8) * 255
        
        # å½¢æ€å­¦ä¼˜åŒ–
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_CLOSE, kernel, iterations=1)
        
        # è¿‡æ»¤å¤§é¢ç§¯åŒºåŸŸï¼ˆå¯èƒ½æ˜¯ä¸»ä½“è€Œä¸æ˜¯æ°´å°ï¼‰
        final_mask = self._filter_large_regions(final_mask, max_ratio=0.02)
        
        if self.debug and output_dir:
            cv2.imwrite(os.path.join(output_dir, 'lc_6_combined.png'), final_mask)
            self._save_preview(image, final_mask, os.path.join(output_dir, 'detection_preview_lc.jpg'))
        
        coverage = np.count_nonzero(final_mask) / final_mask.size * 100
        print(f"ğŸ’¾ Final mask coverage: {coverage:.1f}%")
        
        return final_mask
    
    def _highpass_enhancement(self, image: np.ndarray) -> np.ndarray:
        """
        é«˜é€šæ»¤æ³¢å¢å¼º
        
        åŸç†ï¼š
        - ä½¿ç”¨é«˜æ–¯æ¨¡ç³Šä½œä¸ºä½é€šæ»¤æ³¢å™¨
        - åŸå›¾ - ä½é€š = é«˜é€šï¼ˆé«˜é¢‘ç»†èŠ‚ï¼‰
        - æ°´å°æ–‡å­—çš„è¾¹ç¼˜æ˜¯é«˜é¢‘ä¿¡æ¯
        
        ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼š
        - å¹³æ»‘çš„èƒŒæ™¯åœ¨é«˜é€šæ»¤æ³¢åå“åº”å¾ˆå¼±
        - æ–‡å­—è¾¹ç¼˜åœ¨é«˜é€šæ»¤æ³¢åå“åº”å¾ˆå¼º
        """
        print("ğŸ” Strategy 1: High-pass filter enhancement...")
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32)
        
        # ä½¿ç”¨ä¸åŒå°ºåº¦çš„é«˜é€šæ»¤æ³¢
        masks = []
        
        for blur_size in [3, 7, 15]:
            # ä½é€šï¼šé«˜æ–¯æ¨¡ç³Š
            low_pass = cv2.GaussianBlur(gray, (blur_size, blur_size), 0)
            
            # é«˜é€šï¼šåŸå›¾ - ä½é€š
            high_pass = cv2.absdiff(gray, low_pass)
            
            # å½’ä¸€åŒ–
            high_pass = cv2.normalize(high_pass, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
            
            # è‡ªé€‚åº”é˜ˆå€¼
            thresh = cv2.adaptiveThreshold(
                high_pass, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                cv2.THRESH_BINARY, 11, -2  # è´Ÿåç§»é‡ä½¿é˜ˆå€¼æ›´æ•æ„Ÿ
            )
            masks.append(thresh)
        
        # åˆå¹¶å¤šå°ºåº¦ç»“æœ
        result = np.zeros_like(masks[0])
        for m in masks:
            result = cv2.bitwise_or(result, m)
        
        return result
    
    def _multiscale_dog(self, image: np.ndarray) -> np.ndarray:
        """
        å¤šå°ºåº¦é«˜æ–¯å·®åˆ† (Difference of Gaussians)
        
        åŸç†ï¼š
        - DoG â‰ˆ Laplacian of Gaussian (LoG)
        - DoG(Ïƒ1, Ïƒ2) = G(Ïƒ1) - G(Ïƒ2)
        - å¯ä»¥æ£€æµ‹ç‰¹å®šå°ºåº¦çš„è¾¹ç¼˜å’Œæ–‘ç‚¹
        
        ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼š
        - æ–‡å­—ç¬”ç”»æœ‰ç‰¹å®šçš„å®½åº¦ï¼ˆå‡ ä¸ªåƒç´ ï¼‰
        - é€‰æ‹©åˆé€‚çš„sigmaå¯ä»¥ç²¾ç¡®åŒ¹é…æ–‡å­—ç¬”ç”»å®½åº¦
        - èƒŒæ™¯çº¹ç†é€šå¸¸æ²¡æœ‰è¿™ç§ç‰¹å®šå°ºåº¦çš„ç»“æ„
        """
        print("ğŸ” Strategy 2: Multi-scale Difference of Gaussians...")
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32)
        
        # å¤šå°ºåº¦DoG
        # sigma_pairs: (Ïƒ1, Ïƒ2)ï¼Œæ£€æµ‹å¤§çº¦ Ïƒ1~Ïƒ2 å®½åº¦çš„è¾¹ç¼˜
        sigma_pairs = [(1, 2), (1.5, 3), (2, 4), (3, 6)]
        
        masks = []
        for sigma1, sigma2 in sigma_pairs:
            # è®¡ç®—é«˜æ–¯æ ¸å¤§å°ï¼ˆå¿…é¡»æ˜¯å¥‡æ•°ï¼‰
            k1 = int(6 * sigma1) | 1
            k2 = int(6 * sigma2) | 1
            
            g1 = cv2.GaussianBlur(gray, (k1, k1), sigma1)
            g2 = cv2.GaussianBlur(gray, (k2, k2), sigma2)
            
            # DoG
            dog = cv2.absdiff(g1, g2)
            
            # å½’ä¸€åŒ–å’Œé˜ˆå€¼åŒ–
            dog_norm = cv2.normalize(dog, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
            _, thresh = cv2.threshold(dog_norm, 15, 255, cv2.THRESH_BINARY)
            
            masks.append(thresh)
        
        # åˆå¹¶ç»“æœ
        result = np.zeros_like(masks[0])
        for m in masks:
            result = cv2.bitwise_or(result, m)
        
        return result
    
    def _extreme_local_enhancement(self, image: np.ndarray) -> np.ndarray:
        """
        æç«¯å±€éƒ¨å¢å¼º
        
        åŸç†ï¼š
        - åœ¨éå¸¸å°çš„å±€éƒ¨çª—å£å†…è¿›è¡Œå¯¹æ¯”åº¦å¢å¼º
        - ä½¿ç”¨CLAHEï¼ˆå¯¹æ¯”åº¦å—é™è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰
        - clipLimitè®¾ç½®å¾—å¾ˆé«˜ä»¥è·å¾—æ›´å¼ºçš„å¢å¼ºæ•ˆæœ
        
        ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼š
        - å³ä½¿å…¨å±€å¯¹æ¯”åº¦å¾ˆä½ï¼Œåœ¨3x3æˆ–5x5çš„çª—å£å†…ï¼Œ
          æ°´å°ä¸èƒŒæ™¯ä»å¯èƒ½æœ‰å¾®å°çš„ç°åº¦å·®å¼‚
        - æç«¯çš„å±€éƒ¨å¢å¼ºå¯ä»¥æ”¾å¤§è¿™äº›å¾®å°å·®å¼‚
        """
        print("ğŸ” Strategy 3: Extreme local enhancement...")
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # æç«¯CLAHEå‚æ•°
        # clipLimité«˜ â†’ å¯¹æ¯”åº¦å¢å¼ºæ›´å¼º
        # tileGridSizeå° â†’ å±€éƒ¨åŒ–æ›´å¼º
        clahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(4, 4))
        enhanced = clahe.apply(gray)
        
        # ä¸åŸå›¾åšå·®åˆ†ï¼Œçªå‡ºè¢«å¢å¼ºçš„åŒºåŸŸ
        diff = cv2.absdiff(enhanced, gray)
        
        # å½’ä¸€åŒ–
        diff_norm = cv2.normalize(diff, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        
        # è‡ªé€‚åº”é˜ˆå€¼
        thresh = cv2.adaptiveThreshold(
            diff_norm, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 7, -1
        )
        
        # å¦ä¸€ç§æ–¹æ³•ï¼šä½¿ç”¨æç«¯çš„å±€éƒ¨æ ‡å‡†å·®
        local_std = self._compute_local_std(gray, kernel_size=3)
        std_norm = cv2.normalize(local_std, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        
        # OTSUé˜ˆå€¼
        _, std_thresh = cv2.threshold(std_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # åˆå¹¶ä¸¤ç§æ–¹æ³•
        result = cv2.bitwise_or(thresh, std_thresh)
        
        return result
    
    def _guided_filter_layer(self, image: np.ndarray) -> np.ndarray:
        """
        å¼•å¯¼æ»¤æ³¢åˆ†å±‚
        
        åŸç†ï¼š
        - å¼•å¯¼æ»¤æ³¢å¯ä»¥å°†å›¾åƒåˆ†è§£ä¸ºbaseå’Œdetailä¸¤å±‚
        - baseå±‚æ˜¯å¹³æ»‘çš„å¤§å°ºåº¦ç»“æ„ï¼ˆèƒŒæ™¯ï¼‰
        - detailå±‚æ˜¯é«˜é¢‘ç»†èŠ‚ï¼ˆæ°´å°ã€çº¹ç†ï¼‰
        - æ°´å°ä½œä¸ºå åŠ å±‚ï¼Œåœ¨detailå±‚å¯èƒ½æ›´æ˜æ˜¾
        
        å¼•å¯¼æ»¤æ³¢å…¬å¼ï¼š
        - q = a * I + bï¼ˆå±€éƒ¨çº¿æ€§æ¨¡å‹ï¼‰
        - å…¶ä¸­Iæ˜¯å¼•å¯¼å›¾åƒï¼Œè¿™é‡Œä½¿ç”¨å›¾åƒæœ¬èº«
        
        ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼š
        - å¼•å¯¼æ»¤æ³¢åœ¨è¾¹ç¼˜å¤„ç†ä¸Šä¼˜äºé«˜æ–¯æ»¤æ³¢
        - å¯ä»¥æ›´å¥½åœ°åˆ†ç¦»ä¸åŒçš„å›¾åƒå±‚
        """
        print("ğŸ” Strategy 4: Guided filter layer separation...")
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # OpenCVçš„å¼•å¯¼æ»¤æ³¢
        # radius: æ»¤æ³¢åŠå¾„
        # eps: æ­£åˆ™åŒ–å‚æ•°ï¼Œæ§åˆ¶å¹³æ»‘ç¨‹åº¦
        
        # è·å–baseå±‚ï¼ˆå¹³æ»‘å±‚ï¼‰
        radius = 8
        eps = 0.01 * 255 * 255  # çº¦650
        
        # éœ€è¦float32
        gray_float = gray.astype(np.float32) / 255.0
        
        # å¼•å¯¼æ»¤æ³¢ï¼ˆä½¿ç”¨å›¾åƒæœ¬èº«ä½œä¸ºå¼•å¯¼ï¼‰
        base = cv2.ximgproc.guidedFilter(
            guide=gray_float, 
            src=gray_float, 
            radius=radius, 
            eps=eps
        )
        
        # detailå±‚ = åŸå›¾ - baseå±‚
        detail = gray_float - base
        
        # å¢å¼ºdetailå±‚
        detail_enhanced = np.abs(detail) * 5  # æ”¾å¤§5å€
        detail_enhanced = np.clip(detail_enhanced, 0, 1)
        
        # è½¬æ¢ä¸ºuint8
        detail_uint8 = (detail_enhanced * 255).astype(np.uint8)
        
        # é˜ˆå€¼åŒ–
        _, thresh = cv2.threshold(detail_uint8, 20, 255, cv2.THRESH_BINARY)
        
        return thresh
    
    def _laplacian_enhancement(self, image: np.ndarray) -> np.ndarray:
        """
        Laplacianå¢å¼ºæ£€æµ‹
        
        åŸç†ï¼š
        - Laplacianç®—å­æ˜¯äºŒé˜¶å¯¼æ•°ç®—å­
        - å¯¹è¾¹ç¼˜å“åº”éå¸¸æ•æ„Ÿ
        - å¯ä»¥æ£€æµ‹å¿«é€Ÿå˜åŒ–çš„ç°åº¦åŒºåŸŸï¼ˆæ–‡å­—è¾¹ç¼˜ï¼‰
        
        ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼š
        - æ–‡å­—æœ‰é”åˆ©çš„è¾¹ç¼˜
        - å³ä½¿å¯¹æ¯”åº¦å¾ˆä½ï¼Œè¾¹ç¼˜çš„äºŒé˜¶å¯¼æ•°ä»ä¸ä¸ºé›¶
        """
        print("ğŸ” Strategy 5: Laplacian enhancement...")
        
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # å…ˆè½»å¾®æ¨¡ç³Šå»å™ª
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        
        # Laplacianç®—å­
        # ksize=3: 3x3çš„Laplacianæ ¸
        laplacian = cv2.Laplacian(blurred, cv2.CV_64F, ksize=3)
        
        # å–ç»å¯¹å€¼
        laplacian_abs = np.abs(laplacian)
        
        # å½’ä¸€åŒ–
        lap_norm = cv2.normalize(laplacian_abs, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        
        # è‡ªé€‚åº”é˜ˆå€¼
        thresh = cv2.adaptiveThreshold(
            lap_norm, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 11, -2
        )
        
        return thresh
    
    def _compute_local_std(self, image: np.ndarray, kernel_size: int = 5) -> np.ndarray:
        """è®¡ç®—å±€éƒ¨æ ‡å‡†å·®"""
        image_float = image.astype(np.float64)
        kernel = np.ones((kernel_size, kernel_size), np.float64) / (kernel_size ** 2)
        
        local_mean = cv2.filter2D(image_float, -1, kernel)
        local_sqr_mean = cv2.filter2D(image_float ** 2, -1, kernel)
        
        variance = local_sqr_mean - local_mean ** 2
        variance = np.maximum(variance, 0)
        local_std = np.sqrt(variance)
        
        return local_std.astype(np.float32)
    
    def _filter_large_regions(self, mask: np.ndarray, max_ratio: float = 0.02) -> np.ndarray:
        """
        è¿‡æ»¤å¤§é¢ç§¯åŒºåŸŸ
        
        åŸç†ï¼š
        - æ°´å°é€šå¸¸æ˜¯å°çš„æ–‡å­—åŒºåŸŸ
        - å¤§é¢ç§¯åŒºåŸŸé€šå¸¸æ˜¯ä¸»ä½“æˆ–èƒŒæ™¯
        """
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        h, w = mask.shape
        max_area = h * w * max_ratio
        
        filtered_mask = np.zeros_like(mask)
        
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < max_area and area > 10:  # è¿‡æ»¤è¿‡å¤§å’Œè¿‡å°
                cv2.drawContours(filtered_mask, [cnt], -1, 255, -1)
        
        return filtered_mask
    
    def _save_preview(self, image: np.ndarray, mask: np.ndarray, output_path: str):
        """ä¿å­˜æ£€æµ‹é¢„è§ˆ"""
        preview = image.copy()
        
        # åŠé€æ˜çº¢è‰²è¦†ç›–
        overlay = preview.copy()
        overlay[mask > 127] = [0, 0, 255]
        preview = cv2.addWeighted(overlay, 0.4, preview, 0.6, 0)
        
        # ç»¿è‰²è½®å»“
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(preview, contours, -1, (0, 255, 0), 1)
        
        # ç»Ÿè®¡ä¿¡æ¯
        h, w = preview.shape[:2]
        coverage = np.count_nonzero(mask) / mask.size * 100
        
        cv2.rectangle(preview, (10, 10), (350, 80), (0, 0, 0), -1)
        cv2.putText(preview, f"Low Contrast Detector", (20, 35),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(preview, f"Regions: {len(contours)}", (20, 55),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        cv2.putText(preview, f"Coverage: {coverage:.1f}%", (20, 75),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        cv2.imwrite(output_path, preview)
        print(f"ğŸ“¸ Preview saved: {output_path}")


def main():
    """æµ‹è¯•ä½å¯¹æ¯”åº¦æ£€æµ‹å™¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä½å¯¹æ¯”åº¦æ°´å°æ£€æµ‹å™¨')
    parser.add_argument('-r', '--round', required=True, help='æµ‹è¯•è½®æ¬¡ç›®å½•')
    parser.add_argument('--debug', action='store_true', help='ä¿å­˜ä¸­é—´è°ƒè¯•ç»“æœ')
    
    args = parser.parse_args()
    
    # æ„å»ºè·¯å¾„
    round_dir = f'runs/{args.round}'
    
    # æŸ¥æ‰¾è¾“å…¥å›¾åƒ
    for ext in ['input.png', 'input.jpg', 'sample.png', 'sample.jpg']:
        input_path = os.path.join(round_dir, ext)
        if os.path.exists(input_path):
            break
    else:
        print(f"âŒ No input image found in {round_dir}")
        return
    
    # åŠ è½½å›¾åƒ
    image = cv2.imread(input_path)
    if image is None:
        print(f"âŒ Failed to load image: {input_path}")
        return
    
    print(f"ğŸ¯ Processing: {input_path}")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = LowContrastWatermarkDetector(debug=args.debug)
    
    # æ£€æµ‹
    mask = detector.detect(image, output_dir=round_dir if args.debug else None)
    
    # ä¿å­˜ç»“æœ
    output_path = os.path.join(round_dir, 'mask_low_contrast.png')
    cv2.imwrite(output_path, mask)
    print(f"ğŸ’¾ Mask saved: {output_path}")
    
    print(f"âœ… Detection completed!")


if __name__ == "__main__":
    main()
